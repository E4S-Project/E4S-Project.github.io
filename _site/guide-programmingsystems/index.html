<p style="text-align:center;">
    Construct your prompt from the instructions below then use the E4S Guide Bot
</p>
<style>
/* E4S theme-adaptive pill button with white text */
.btn--e4s {
  background-color: var(--e4s-blue);
  color: #ffffff !important;
  border: none;
  border-radius: 9999px;
  padding: 0.6em 1.6em;
  font-weight: 600;
  display: inline-block;
  transition: background-color 0.2s ease-in-out, color 0.2s ease-in-out;
  text-decoration: none;
}
.btn--e4s:hover,
.btn--e4s:focus {
  background-color: var(--e4s-blue-hover);
  color: #ffffff !important;
  text-decoration: none;
}
:root {
  --e4s-blue: #0092ca;
  --e4s-blue-hover: #006b99;
}
[data-theme="dark"] {
  --e4s-blue: #33b8f2;
  --e4s-blue-hover: #66ccff;
}
</style>

<p style="text-align:center;">
  <a href="https://chatgpt.com/g/g-69010fb294b0819195727cf1a7ccc792-software-ecosystem-for-science-guide" class="btn btn--e4s">Chat with the E4S Guide Bot</a>
</p>

<h2 id="introduction">Introduction</h2>

<p>Selecting an appropriate parallel programming system is a key step in developing efficient, portable, and maintainable scientific applications. The E4S ecosystem provides a curated collection of programming models, frameworks, and libraries designed to help developers achieve high performance across diverse architectures including multicore CPUs, manycore GPUs, and emerging accelerators.</p>

<p>When choosing a programming system, it is important to consider factors such as portability, interoperability, runtime overhead, and developer productivity. For instance, a user running on a large GPU-based system might prioritize asynchronous execution and memory management models, while another working with mixed Fortran and C++ codebases might focus on compiler support and interoperability layers.</p>

<p>To help newcomers navigate these choices, the following sections define attributes that describe both general and specialized considerations for selecting a parallel programming system or library. These attributes can be used to formulate a detailed prompt for a chatbot or recommender tool to suggest suitable E4S products.</p>

<h2 id="example-prompt">Example Prompt</h2>

<blockquote>
  <p>I am developing a simulation code in C++ that needs to run efficiently on both NVIDIA and AMD GPUs. I prefer to use a performance-portable library that integrates with MPI for distributed memory and supports OpenMP on CPUs. I would like to minimize the need for vendor-specific code changes and ensure good support for asynchronous execution and profiling tools.</p>
</blockquote>

<hr />

<h2 id="broadly-meaningful-attributes-for-programming-systems">Broadly Meaningful Attributes for Programming Systems</h2>

<table>
  <thead>
    <tr>
      <th>Attribute</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Target architectures</td>
      <td>The types of architectures supported, such as CPUs, GPUs, or multi-accelerator systems.</td>
    </tr>
    <tr>
      <td>Programming languages</td>
      <td>The primary languages supported (C, C++, Fortran, Python).</td>
    </tr>
    <tr>
      <td>Portability model</td>
      <td>The extent to which the programming system allows running on multiple vendorsâ€™ hardware with minimal changes.</td>
    </tr>
    <tr>
      <td>Performance portability</td>
      <td>How effectively the framework can deliver performance across architectures without rewriting kernels.</td>
    </tr>
    <tr>
      <td>Abstraction level</td>
      <td>The level of abstraction provided, from low-level APIs to high-level frameworks.</td>
    </tr>
    <tr>
      <td>Integration with MPI</td>
      <td>Whether the system supports or interoperates with MPI for inter-node communication.</td>
    </tr>
    <tr>
      <td>Memory model</td>
      <td>How data movement and memory management are handled between host and device.</td>
    </tr>
    <tr>
      <td>Asynchronous execution</td>
      <td>Support for task-based or asynchronous parallelism.</td>
    </tr>
    <tr>
      <td>Debugging and profiling support</td>
      <td>Availability of integrated tools or external support for performance analysis.</td>
    </tr>
    <tr>
      <td>Community and documentation</td>
      <td>The strength of community support, user guides, and active development.</td>
    </tr>
    <tr>
      <td>Licensing and openness</td>
      <td>Availability under open-source licenses and alignment with E4S standards.</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="attributes-for-specific-situations">Attributes for Specific Situations</h2>

<h3 id="intra-node-systems">Intra-Node Systems</h3>

<table>
  <thead>
    <tr>
      <th>Attribute</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Shared memory model</td>
      <td>Whether the system supports shared memory parallelism (e.g., OpenMP, CUDA threads).</td>
    </tr>
    <tr>
      <td>Task scheduling</td>
      <td>Support for dynamic task scheduling or work-stealing mechanisms.</td>
    </tr>
    <tr>
      <td>Thread affinity and control</td>
      <td>Ability to control thread placement and binding for NUMA systems.</td>
    </tr>
    <tr>
      <td>Vectorization support</td>
      <td>Level of compiler or library-assisted vectorization.</td>
    </tr>
    <tr>
      <td>GPU kernel execution model</td>
      <td>Control and flexibility in defining and launching GPU kernels.</td>
    </tr>
    <tr>
      <td>Device memory hierarchy awareness</td>
      <td>Capability to utilize L1/L2 caches and shared memory efficiently.</td>
    </tr>
    <tr>
      <td>Compiler dependencies</td>
      <td>Required or preferred compiler infrastructure (LLVM, GCC, NVHPC, etc.).</td>
    </tr>
  </tbody>
</table>

<hr />

<h3 id="inter-node-systems">Inter-Node Systems</h3>

<table>
  <thead>
    <tr>
      <th>Attribute</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Communication model</td>
      <td>Message passing or PGAS-based communication model.</td>
    </tr>
    <tr>
      <td>Latency and bandwidth optimization</td>
      <td>Support for minimizing communication overhead and optimizing collective operations.</td>
    </tr>
    <tr>
      <td>Fault tolerance</td>
      <td>Capabilities for checkpoint/restart or resilience in distributed environments.</td>
    </tr>
    <tr>
      <td>Overlap of communication and computation</td>
      <td>Ability to perform asynchronous communications with concurrent computation.</td>
    </tr>
    <tr>
      <td>Network portability</td>
      <td>Compatibility with InfiniBand, Slingshot, Ethernet, and other HPC interconnects.</td>
    </tr>
    <tr>
      <td>Integration with resource managers</td>
      <td>Interoperability with job schedulers such as SLURM or Flux.</td>
    </tr>
    <tr>
      <td>Hybrid parallelism</td>
      <td>Support for combining distributed and shared-memory parallel models (MPI + threads).</td>
    </tr>
    <tr>
      <td>Performance analysis hooks</td>
      <td>Interfaces to collect inter-node communication traces and performance metrics.</td>
    </tr>
  </tbody>
</table>

<hr />

<h3 id="language-supported-systems-modern-fortran-and-c-via-llvm-compilers">Language-Supported Systems (Modern Fortran and C++ via LLVM Compilers)</h3>

<table>
  <thead>
    <tr>
      <th>Attribute</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Standard support level</td>
      <td>Compliance with Fortran 2008+, C++17+, or newer standards.</td>
    </tr>
    <tr>
      <td>Compiler-based directives</td>
      <td>Availability of OpenMP, OpenACC, or SYCL support in the compiler.</td>
    </tr>
    <tr>
      <td>Unified memory model</td>
      <td>Simplified access to device and host memory through unified memory.</td>
    </tr>
    <tr>
      <td>Template and metaprogramming features</td>
      <td>Ability to define portable kernels using C++ templates or Fortran coarrays.</td>
    </tr>
    <tr>
      <td>Integration with performance libraries</td>
      <td>Direct compatibility with BLAS, LAPACK, KokkosKernels, or other math libraries.</td>
    </tr>
    <tr>
      <td>Compiler optimization maturity</td>
      <td>Level of maturity and stability of compiler optimizations for each architecture.</td>
    </tr>
    <tr>
      <td>Language interoperability</td>
      <td>Ease of calling C/C++ libraries from Fortran or vice versa.</td>
    </tr>
    <tr>
      <td>Toolchain integration</td>
      <td>Integration with LLVM-based analysis, debugging, and profiling tools.</td>
    </tr>
    <tr>
      <td>Vendor backend support</td>
      <td>Availability of target backends (NVIDIA, AMD, Intel, ARM) through the compiler toolchain.</td>
    </tr>
  </tbody>
</table>
